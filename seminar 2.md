[[2025-07-11]]
## simultaneous ultrahigh temporal-spatial resolution for Quantum materials
the challenge of probing non-equillibrium states is Rayligh distinct limit.
without spatial, we cannot distinct the non-equillibrium clearly and can only observe the beginning state and ending state without ultrahigh temporal resolution.

---
Theory of the scanning probe microscopy: atomic force microscope (AFM), is that the probe will oscillate near the sample because the Force$F_{ts}=$Pauli repulsion+Chemical force+Van der Waals force. Which is High resolution at the scale ~1A.
Actually, the chemical bond has been shown in AFM image.

---
the basic idea for probe T1 lifetimes:
1. when there is only one atom, prepare T1, and let it decayl probe the outcome
2. we repeat it for statistics.

## Ai for science
- what is HEP experiment
- what can LLM do for HEP? Automation
the machine learning is to combine different module into one. the brain behind Ai are totally LLM(large language model). It's improtant because we always translate our study into natural language, we also communicate with human with it.
impressive porformance: can it be the game changer? thr training is aiming to allow them to understand the rules behind human words.
How large? more than 2000 billion parameters, for reference, number of neurons in human brain is about 100 billion, but most langrage model is less clever than humans.
but up to now,  there are still few options that LLM can do to help us, maybe the most useful one is only Generating code. indeed LLMs are not thinking but statistic. 
all the opinions above were generated by chatgpt, but not next.

---
### collider experience of HEP 
Currently we have one collider at China, for the collider there are some prototype described in novels.(why should i note this?)
the summary of the opinions of the Nobel prize winners is that AI well change HEP study significantly, but no as creative as human.

so the answer of what can LLM do for HEP is just assistant as a chatbot and automation: Take LLM as a controller, generate configuration or programs to control the scientific tool.

RAG is Retrieval-Augented-Generation,  which is the most cheap and promosing way to provide database according to the information that used to be there.
*AccGPT for LHC* is an Ai assistant at CERN, enhance CERN knowledge retrieval
HEP data analysis is complex. so difficult to model the analysis workflow. the total lines of code is lager than 5M, similar to windows or macOS

the key development of *Dr Sai* is to analysis the logic behind our knowledge: the scientists translate their physic research or other knowledge into fake code ( in form of algorithm), which named as Domain-Specific-Language(DSL). and BASII has at least 600 research results.

### future
One possible approach is  foundation model(FM), who is built on multi-moldal experimental data, one subdetector which is same as another fully different modal. 
**Fluff course**

---
### what is HEP?
the scientific hunting for the unknown unknowns. ant there is many more thchnical challenges where AI is useful and has been used, and it shows up again to emphasize the large scale streaming date rate the HEP needs.

---
